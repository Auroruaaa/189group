{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import mne\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "task_mapping = {\n",
    "    # 1: \"baseline\", 2: \"baseline\",\n",
    "    3: \"task1\", 7: \"task1\", 11: \"task1\",\n",
    "    4: \"task2\",  8: \"task2\",12: \"task2\",\n",
    "    5: \"task3\",  9: \"task3\", 13: \"task3\",\n",
    "    6: \"task4\", 10: \"task4\", 14: \"task4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_epochs_with_offset(raw, duration, overlap, offset_sec=0.0):\n",
    "    raw_offset = raw.copy()\n",
    "    raw_offset.crop(tmin=offset_sec, tmax=None)\n",
    "    epochs = mne.make_fixed_length_epochs(\n",
    "        raw_offset, duration=duration, overlap=overlap, preload=True, verbose=False\n",
    "    )\n",
    "    return epochs\n",
    "\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def load_eeg_data(edf_file_path, baseline_files=None):\n",
    "    raw = mne.io.read_raw_edf(edf_file_path, preload=True, verbose=False)\n",
    "    raw.pick(['Cz..', 'C3..', 'C4..'])\n",
    "    raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "\n",
    "    event_times = raw.annotations.onset\n",
    "    event_labels = raw.annotations.description\n",
    "    label_mapping = {'T0': 0, 'T1': 1, 'T2': 2}\n",
    "    event_ids = np.array([label_mapping[label] for label in event_labels])\n",
    "\n",
    "    events = np.zeros((len(event_times), 3), dtype=int)\n",
    "    events[:, 0] = (event_times * raw.info['sfreq']).astype(int)\n",
    "    events[:, -1] = event_ids\n",
    "\n",
    "    event_id = {key: value for key, value in label_mapping.items()}\n",
    "\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, event_id=event_id, tmin=-0.2, tmax=1.0,\n",
    "        baseline=(None, 0), preload=True, verbose=False\n",
    "    )\n",
    "\n",
    "    # if baseline_files:\n",
    "    #     baseline_data = []\n",
    "    #     for baseline_file in baseline_files:\n",
    "\n",
    "    #         baseline_raw = mne.io.read_raw_edf(baseline_file, preload=True, verbose=False)\n",
    "    #         baseline_raw.pick(['Cz..', 'C3..', 'C4..'])\n",
    "    #         baseline_data.append(baseline_raw.get_data())\n",
    "\n",
    "    #     baseline_mean = np.mean(np.concatenate(baseline_data, axis=0), axis=0)\n",
    "    #     epochs._data -= baseline_mean\n",
    "\n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./files/\"\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for subject in sorted(os.listdir(root_dir)):\n",
    "    subject_path = os.path.join(root_dir, subject)\n",
    "    \n",
    "    if os.path.isdir(subject_path) and re.match(r\"S\\d{3}\", subject):\n",
    "        # control the number of persons\n",
    "        if(i < 30):\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        edf_files = sorted([f for f in os.listdir(subject_path) if f.endswith(\".edf\")])\n",
    "\n",
    "        baseline_files = [os.path.join(subject_path, f) for f in edf_files if re.match(rf\"{subject}R0[12]\\.edf\", f)]\n",
    "\n",
    "        for edf_file in edf_files:\n",
    "            match = re.match(r\"(S\\d{3})R(\\d{2})\\.edf\", edf_file)\n",
    "            if match:\n",
    "                subject_id, session_id = match.groups()\n",
    "                session_id = int(session_id)\n",
    "\n",
    "                if session_id in task_mapping:\n",
    "                    task = task_mapping[session_id]\n",
    "                    full_path = os.path.join(subject_path, edf_file)\n",
    "\n",
    "                    if subject_id not in data_dict:\n",
    "                        data_dict[subject_id] = {task: []}\n",
    "                    if task not in data_dict[subject_id]:\n",
    "                        data_dict[subject_id][task] = []\n",
    "                    \n",
    "                    data_dict[subject_id][task].append((full_path, baseline_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files = [], []\n",
    "\n",
    "for subject_id, tasks in data_dict.items():\n",
    "    for task, file_list in tasks.items():\n",
    "        if len(file_list) >= 3:\n",
    "            train_files.extend(file_list[:2])\n",
    "            test_files.append(file_list[2])\n",
    "\n",
    "class EEGMotorImageryDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for file_path, baseline_files in self.file_list:\n",
    "            epochs = load_eeg_data(file_path, baseline_files)\n",
    "\n",
    "            self.data.append(epochs.get_data())\n",
    "            self.labels.append(epochs.events[:, -1])\n",
    "\n",
    "       \n",
    "        self.data = np.concatenate(self.data, axis=0).astype(np.float32)\n",
    "        self.labels = np.concatenate(self.labels, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        sample = sample[np.newaxis, :, :]\n",
    "        return torch.tensor(sample), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = EEGMotorImageryDataset(train_files)\n",
    "test_dataset = EEGMotorImageryDataset(test_files)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_shape: (6960, 579), Test_shape: (3480, 579)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_dataloader_to_numpy(dataloader):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_list.append(X_batch.numpy())\n",
    "        y_list.append(y_batch.numpy())\n",
    "\n",
    "    X_array = np.concatenate(X_list, axis=0)\n",
    "    y_array = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    return X_array, y_array\n",
    "\n",
    "X_train, y_train = convert_dataloader_to_numpy(train_loader)\n",
    "X_test, y_test = convert_dataloader_to_numpy(test_loader)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"Train_shape: {X_train.shape}, Test_shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1680,  908,  892]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.68%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([2669,  247,  564]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.22%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"num_class\": len(np.unique(y_train)),\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "y_pred = bst.predict(dtest)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.], dtype=float32), array([2314,  503,  663]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(1, 64), padding=(0, 32))\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(2, 32), groups=16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d((1, 8))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(1, 16), padding=(0, 8))\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d((1, 4))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        if self.fc is None:\n",
    "            feature_dim = x.shape[1]\n",
    "            self.fc = nn.Linear(feature_dim, 4).to(x.device)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 1.0347491421287174 | Test Accuracy: 48.30%\n",
      "Epoch 2/20 | Loss: 0.9626098852476169 | Test Accuracy: 26.47%\n",
      "Epoch 3/20 | Loss: 0.9505818949990916 | Test Accuracy: 48.48%\n",
      "Epoch 4/20 | Loss: 0.9416262277059428 | Test Accuracy: 48.48%\n",
      "Epoch 5/20 | Loss: 0.9340976879707185 | Test Accuracy: 1.61%\n",
      "Epoch 6/20 | Loss: 0.9311169998003063 | Test Accuracy: 48.30%\n",
      "Epoch 7/20 | Loss: 0.9297325859948907 | Test Accuracy: 38.28%\n",
      "Epoch 8/20 | Loss: 0.9293498419428609 | Test Accuracy: 48.56%\n",
      "Epoch 9/20 | Loss: 0.9220344004103507 | Test Accuracy: 48.94%\n",
      "Epoch 10/20 | Loss: 0.9225968111456296 | Test Accuracy: 48.25%\n",
      "Epoch 11/20 | Loss: 0.9201991809125262 | Test Accuracy: 48.30%\n",
      "Epoch 12/20 | Loss: 0.9213423543620384 | Test Accuracy: 48.88%\n",
      "Epoch 13/20 | Loss: 0.9192601781862991 | Test Accuracy: 46.29%\n",
      "Epoch 14/20 | Loss: 0.9181311266550302 | Test Accuracy: 26.70%\n",
      "Epoch 15/20 | Loss: 0.9187802566964736 | Test Accuracy: 25.72%\n",
      "Epoch 16/20 | Loss: 0.9181180224143739 | Test Accuracy: 31.70%\n",
      "Epoch 17/20 | Loss: 0.9146891977166992 | Test Accuracy: 49.08%\n",
      "Epoch 18/20 | Loss: 0.9174806722991126 | Test Accuracy: 45.06%\n",
      "Epoch 19/20 | Loss: 0.9120505442532401 | Test Accuracy: 48.30%\n",
      "Epoch 20/20 | Loss: 0.9107375346188401 | Test Accuracy: 33.19%\n",
      "Test Accuracy: 33.19%\n"
     ]
    }
   ],
   "source": [
    "model = EEGNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        y = y.long()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss / len(train_loader)} | Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
