{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b372a17-603c-4b0e-b372-85e5e849c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcec4bf",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cc609",
   "metadata": {},
   "source": [
    "### Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c985369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_epochs_with_offset(raw, duration, overlap, offset_sec=0.0):\n",
    "    raw_offset = raw.copy()\n",
    "    raw_offset.crop(tmin=offset_sec, tmax=None)\n",
    "    \n",
    "    epochs = mne.make_fixed_length_epochs(\n",
    "        raw_offset,\n",
    "        duration=duration,\n",
    "        overlap=overlap,\n",
    "        preload=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62eefee8-1a40-4c08-be63-f7bcf18fbf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "9920 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aabla\\AppData\\Local\\Temp\\ipykernel_19352\\2229215875.py:20: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined = mne.concatenate_epochs([epochs1, epochs2])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    // must be `var` (not `const`) because this can get embedded multiple times on a page\n",
       "var toggleVisibility = (className) => {\n",
       "\n",
       "    const elements = document.querySelectorAll(`.${className}`);\n",
       "\n",
       "    elements.forEach(element => {\n",
       "        if (element.classList.contains(\"mne-repr-section-header\")) {\n",
       "            return  // Don't collapse the section header row\n",
       "        }\n",
       "        element.classList.toggle(\"mne-repr-collapsed\");\n",
       "    });\n",
       "\n",
       "    // trigger caret to rotate\n",
       "    var sel = `.mne-repr-section-header.${className} > th.mne-repr-section-toggle > button`;\n",
       "    const button = document.querySelector(sel);\n",
       "    button.classList.toggle(\"collapsed\");\n",
       "\n",
       "    // adjust tooltip\n",
       "    sel = `tr.mne-repr-section-header.${className}`;\n",
       "    const secHeadRow = document.querySelector(sel);\n",
       "    secHeadRow.classList.toggle(\"collapsed\");\n",
       "    secHeadRow.title = secHeadRow.title === \"Hide section\" ? \"Show section\" : \"Hide section\";\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    /*\n",
       "Styles in this section apply both to the sphinx-built website docs and to notebooks\n",
       "rendered in an IDE or in Jupyter. In our web docs, styles here are complemented by\n",
       "doc/_static/styles.css and other CSS files (e.g. from the sphinx theme, sphinx-gallery,\n",
       "or bootstrap). In IDEs/Jupyter, those style files are unavailable, so only the rules in\n",
       "this file apply (plus whatever default styling the IDE applies).\n",
       "*/\n",
       ".mne-repr-table {\n",
       "    display: inline;  /* prevent using full container width */\n",
       "}\n",
       ".mne-repr-table tr.mne-repr-section-header > th {\n",
       "    padding-top: 1rem;\n",
       "    text-align: left;\n",
       "    vertical-align: middle;\n",
       "}\n",
       ".mne-repr-section-toggle > button {\n",
       "    all: unset;\n",
       "    display: block;\n",
       "    height: 1rem;\n",
       "    width: 1rem;\n",
       "}\n",
       ".mne-repr-section-toggle > button > svg {\n",
       "    height: 60%;\n",
       "}\n",
       "\n",
       "/* transition (rotation) effects on the collapser button */\n",
       ".mne-repr-section-toggle > button.collapsed > svg {\n",
       "    transition: 0.1s ease-out;\n",
       "    transform: rotate(-90deg);\n",
       "}\n",
       ".mne-repr-section-toggle > button:not(.collapsed) > svg {\n",
       "    transition: 0.1s ease-out;\n",
       "    transform: rotate(0deg);\n",
       "}\n",
       "\n",
       "/* hide collapsed table rows */\n",
       ".mne-repr-collapsed {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "\n",
       "@layer {\n",
       "    /*\n",
       "    Selectors in a `@layer` will always be lower-precedence than selectors outside the\n",
       "    layer. So even though e.g. `div.output_html` is present in the sphinx-rendered\n",
       "    website docs, the styles here won't take effect there as long as some other rule\n",
       "    somewhere in the page's CSS targets the same element.\n",
       "\n",
       "    In IDEs or Jupyter notebooks, though, the CSS files from the sphinx theme,\n",
       "    sphinx-gallery, and bootstrap are unavailable, so these styles will apply.\n",
       "\n",
       "    Notes:\n",
       "\n",
       "    - the selector `.accordion-body` is for MNE Reports\n",
       "    - the selector `.output_html` is for VSCode's notebook interface\n",
       "    - the selector `.jp-RenderedHTML` is for Jupyter notebook\n",
       "    - variables starting with `--theme-` are VSCode-specific.\n",
       "    - variables starting with `--jp-` are Jupyter styles, *some of which* are also\n",
       "      available in VSCode. Here we try the `--theme-` variable first, then fall back to\n",
       "      the `--jp-` ones.\n",
       "    */\n",
       "    .mne-repr-table {\n",
       "        --mne-toggle-color: var(--theme-foreground, var(--jp-ui-font-color1));\n",
       "        --mne-button-bg-color: var(--theme-button-background, var(--jp-info-color0, var(--jp-content-link-color)));\n",
       "        --mne-button-fg-color: var(--theme-button-foreground, var(--jp-ui-inverse-font-color0, var(--jp-editor-background)));\n",
       "        --mne-button-hover-bg-color: var(--theme-button-hover-background, var(--jp-info-color1));\n",
       "        --mne-button-radius: var(--jp-border-radius, 0.25rem);\n",
       "    }\n",
       "    /* chevron position/alignment; in VSCode it looks ok without adjusting */\n",
       "    .accordion-body .mne-repr-section-toggle > button,\n",
       "    .jp-RenderedHTML .mne-repr-section-toggle > button {\n",
       "        padding: 0 0 45% 25% !important;\n",
       "    }\n",
       "    /* chevron color; MNE Report doesn't have light/dark mode */\n",
       "    div.output_html .mne-repr-section-toggle > button > svg > path,\n",
       "    .jp-RenderedHTML .mne-repr-section-toggle > button > svg > path {\n",
       "        fill: var(--mne-toggle-color);\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn,\n",
       "    div.output_html .mne-ch-names-btn,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn {\n",
       "        -webkit-border-radius: var(--mne-button-radius);\n",
       "        -moz-border-radius: var(--mne-button-radius);\n",
       "        border-radius: var(--mne-button-radius);\n",
       "        border: none;\n",
       "        background-image: none;\n",
       "        background-color: var(--mne-button-bg-color);\n",
       "        color: var(--mne-button-fg-color);\n",
       "        font-size: inherit;\n",
       "        min-width: 1.5rem;\n",
       "        padding: 0.25rem;\n",
       "        text-align: center;\n",
       "        text-decoration: none;\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn:hover,\n",
       "    div.output_html .mne.ch-names-btn:hover,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn:hover {\n",
       "        background-color: var(--mne-button-hover-bg-color);\n",
       "        text-decoration: underline;\n",
       "    }\n",
       "    .accordion-body .mne-ch-names-btn:focus-visible,\n",
       "    div.output_html .mne-ch-names-btn:focus-visible,\n",
       "    .jp-RenderedHTML .mne-ch-names-btn:focus-visible {\n",
       "        outline: 0.1875rem solid var(--mne-button-bg-color) !important;\n",
       "        outline-offset: 0.1875rem !important;\n",
       "    }\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"table mne-repr-table\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>EpochsArray</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>2009-08-12 at 16:15:00 UTC</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    \n",
       "    <td>X</td>\n",
       "    \n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-29958f81-9fd1-4d9c-a33c-2fd908c83f0f \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header acquisition-5bfc127e-0826-448f-8bfc-b67db5017910\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('acquisition-5bfc127e-0826-448f-8bfc-b67db5017910')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Total number of events</td>\n",
       "    <td>9920</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Events counts</td>\n",
       "    \n",
       "    <td>\n",
       "        \n",
       "        1: 9920\n",
       "        \n",
       "        \n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Time range</td>\n",
       "    <td>0.000 – 0.994 s</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Baseline</td>\n",
       "    <td>off</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>160.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Time points</td>\n",
       "    <td>160</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-5bfc127e-0826-448f-8bfc-b67db5017910 \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Metadata</td>\n",
       "    <td>No metadata set</td>\n",
       "</tr>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header channels-b921816a-116a-4ed4-98dc-2c41ac44751a\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-b921816a-116a-4ed4-98dc-2c41ac44751a')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "    \n",
       "<tr class=\"repr-element channels-b921816a-116a-4ed4-98dc-2c41ac44751a \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"mne-ch-names-btn sd-sphinx-override sd-btn sd-btn-info sd-text-wrap sd-shadow-sm\" onclick=\"alert('Good EEG:\\n\\nOz.., T7.., Cz..')\" title=\"(Click to open in popup)&#13;&#13;Oz.., T7.., Cz..\">\n",
       "            3\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-b921816a-116a-4ed4-98dc-2c41ac44751a \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>Not available</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"mne-repr-section-header filters-39eda148-0541-489c-90e9-749140aa569c\"\n",
       "     title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-39eda148-0541-489c-90e9-749140aa569c')\">\n",
       "    <th class=\"mne-repr-section-toggle\">\n",
       "        <button >\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d=\"M233.4 406.6c12.5 12.5 32.8 12.5 45.3 0l192-192c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L256 338.7 86.6 169.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l192 192z\"/></svg>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-39eda148-0541-489c-90e9-749140aa569c \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>1.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-39eda148-0541-489c-90e9-749140aa569c \">\n",
       "    <td class=\"mne-repr-section-toggle\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>40.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray | 9920 events (all good), 0 – 0.994 s (baseline off), ~36.3 MiB, data loaded,\n",
       " '1': 9920>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_eeg_data(file_path):\n",
    "    raw = mne.io.read_raw_edf(file_path, preload = True, verbose = False)\n",
    "    raw.pick(['Oz..', 'T7..', 'Cz..'])    \n",
    "    raw.filter(1., 40., fir_design = 'firwin', verbose = False)\n",
    "\n",
    "    T_sec = 1\n",
    "    stride_sec = 4 / 160\n",
    "    offset_sec = 8/160\n",
    "    overlap = T_sec - stride_sec\n",
    "    \n",
    "    # Pass 1: no offset\n",
    "    epochs1 = make_sliding_epochs_with_offset(\n",
    "        raw, duration=T_sec, overlap=overlap, offset_sec=0.0\n",
    "    )\n",
    "    \n",
    "    # Pass 2: offset_sec\n",
    "    epochs2 = make_sliding_epochs_with_offset(\n",
    "        raw, duration=T_sec, overlap=overlap, offset_sec=offset_sec\n",
    "    )\n",
    "    combined = mne.concatenate_epochs([epochs1, epochs2])\n",
    "    return combined\n",
    "\n",
    "eeg_file_path = r'\\Users\\aabla\\OneDrive\\Desktop\\Authenticators\\files\\S003\\S003R03.edf'\n",
    "epochs = load_eeg_data(eeg_file_path)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60257e4",
   "metadata": {},
   "source": [
    "### Visualize Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25917848-8937-4f15-8c6f-a683ab02cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot(n_epochs = 10, n_channels = 3, scalings = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa4ee5",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f3879-1255-4c2c-8808-4aca3cd32378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGMotorImageryDataset(Dataset):\n",
    "    def __init__(self, epochs):\n",
    "        self.data = epochs.get_data()\n",
    "        self.labels = epochs.events[:,-1]\n",
    "\n",
    "        self.data = (self.data - np.mean(self.data, axis = 2, keepdims = True)) / np.std(self.data, axis = 2, keepdims = True)\n",
    "        self.data = self.data.astype(np.float32)\n",
    "\n",
    "        self.indices_by_class = {}\n",
    "        for i, label in enumerate(self.labels):\n",
    "            self.indices_by_class.setdefault(label, []).append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        sample = sample[np.newaxis,:,:]\n",
    "        return sample, label\n",
    "\n",
    "base_dataset = EEGMotorImageryDataset(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45e562-b422-4195-9e8f-1d90d655eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    sample, label = base_dataset[i]\n",
    "    # Remove the singleton dimension (1, n_channels, n_times) -> (n_channels, n_times)\n",
    "    sample = sample.squeeze(0)\n",
    "    n_channels, n_times = sample.shape\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for ch in range(n_channels):\n",
    "        plt.plot(sample[ch], label=f\"Channel {ch}\")\n",
    "    plt.title(f\"Sample {i} - Label: {label}\")\n",
    "    plt.xlabel(\"Time points\")\n",
    "    plt.ylabel(\"Normalized Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465e296",
   "metadata": {},
   "source": [
    "## Siamse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10762e4e-9bc9-41de-94d6-b567e31dffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseEEGMotorImageryDataset(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.data = base_dataset.data\n",
    "        self.labels = base_dataset.labels\n",
    "        self.indices_by_class = base_dataset.indices_by_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample1, label1 = self.basedataset[idx]\n",
    "\n",
    "        similar = np.random.randit(0,2)\n",
    "\n",
    "        if similar:\n",
    "            indices = self.indices_by_class[label1]\n",
    "            idx2 = idx\n",
    "            while idx2 == idx:\n",
    "                idx2 = np.random.choice(indices)\n",
    "        else:\n",
    "            other_classes = list(self.indices_by_class.keys())\n",
    "            other_classes.remove(label1)\n",
    "            chosen_label = np.random.choice(other_classes)\n",
    "            idx2 = np.random.choice(self.indices_by_class[chosen_label])\n",
    "\n",
    "        sample2, label2 = self.base_dataset[idx2] \n",
    "        similarity = 1 if label1 == label2 else 0\n",
    "        return sample1, sample2, np.array([similarity], dtype = np.float32)\n",
    "\n",
    "siamese_dataset = SiameseEEGMotorImageryDataset(base_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac536ab-ff91-4c71-ab15-56b9f7431c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "loader = DataLoader(siamese_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64b9cd",
   "metadata": {},
   "source": [
    "## EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb3847-4e28-4c63-b8c1-1250a00dd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 1\n",
    "F1 = 8\n",
    "D = 2\n",
    "F2 = 16\n",
    "\n",
    "kernel_size_1 = (1, 64)  \n",
    "kernel_padding_1 = (0, 32)\n",
    "kernel_size_2 = (2, 32)  \n",
    "kernel_avgpool_1 = (1, 8)\n",
    "dropout_rate = 0.5\n",
    "kernel_size_3 = (1, 16)  \n",
    "kernel_padding_3 = (0, 8)\n",
    "kernel_size_4 = (1, 1)   \n",
    "kernel_avgpool_2 = (1, 4)\n",
    "signal_length = 256      \n",
    "num_class = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a19e4-7f85-4236-8c38-5a492eac9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNetFeature(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(EEGNetFeature, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv2d = nn.Conv2d(num_input, F1, kernel_size=kernel_size_1, padding=kernel_padding_1)\n",
    "        self.Batch_normalization_1 = nn.BatchNorm2d(F1)\n",
    "        # Layer 2\n",
    "        self.Depthwise_conv2D = nn.Conv2d(F1, D * F1, kernel_size=kernel_size_2, groups=F1)\n",
    "        self.Batch_normalization_2 = nn.BatchNorm2d(D * F1)\n",
    "        self.Elu = nn.ELU()\n",
    "        self.Average_pooling2D_1 = nn.AvgPool2d(kernel_avgpool_1)\n",
    "        self.Dropout = nn.Dropout2d(dropout_rate)\n",
    "        # Layer 3\n",
    "        self.Separable_conv2D_depth = nn.Conv2d(D * F1, D * F1, kernel_size=kernel_size_3,\n",
    "                                                 padding=kernel_padding_3, groups=D * F1)\n",
    "        self.Separable_conv2D_point = nn.Conv2d(D * F1, F2, kernel_size=kernel_size_4)\n",
    "        self.Batch_normalization_3 = nn.BatchNorm2d(F2)\n",
    "        self.Average_pooling2D_2 = nn.AvgPool2d(kernel_avgpool_2)\n",
    "        # Layer 4\n",
    "        self.Flatten = nn.Flatten()\n",
    "        # Compute the flattened feature size. This depends on your input signal size.\n",
    "        # Here we assume the pooling operations reduce the time dimension by a factor of 32.\n",
    "        self.Dense = nn.Linear(F2 * (round(signal_length / 32)), num_class)\n",
    "        # Note: we remove the Softmax to get raw embeddings (or logits) for the siamese branch\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        y = self.conv2d(x)\n",
    "        y = self.Batch_normalization_1(y)\n",
    "        # Layer 2\n",
    "        y = self.Depthwise_conv2D(y)\n",
    "        y = self.Batch_normalization_2(y)\n",
    "        y = self.Elu(y)\n",
    "        y = self.Average_pooling2D_1(y)\n",
    "        y = self.Dropout(y)\n",
    "        # Layer 3\n",
    "        y = self.Separable_conv2D_depth(y)\n",
    "        y = self.Separable_conv2D_point(y)\n",
    "        y = self.Batch_normalization_3(y)\n",
    "        y = self.Elu(y)\n",
    "        y = self.Average_pooling2D_2(y)\n",
    "        y = self.Dropout(y)\n",
    "        # Layer 4\n",
    "        y = self.Flatten(y)\n",
    "        y = self.Dense(y)\n",
    "        return y  # These are your embeddings (or logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ad629",
   "metadata": {},
   "source": [
    "## SiameseEEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba053b94-f6b0-4c6a-8a74-86a64d19d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseEEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseEEGNet, self).__init__()\n",
    "        # Shared EEGNet feature extractor (weights will be shared for both inputs)\n",
    "        self.feature_extractor = EEGNetFeature()\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        # Get embeddings for both inputs\n",
    "        embed1 = self.feature_extractor(x1)\n",
    "        embed2 = self.feature_extractor(x2)\n",
    "        cos_sim = F.cosine_similarity(embed1, embed2, dim=1, eps=1e-6)\n",
    "        # Optionally, you can reshape it to (batch_size, 1) if needed.\n",
    "        return embed1, embed2, cos_sim.unsqueeze(1)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create the Siamese model instance\n",
    "siamese_model = SiameseEEGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03389839-d086-46db-8352-b406b73b2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have two inputs (e.g., two EEG signals) with shape [batch_size, channels, height, width]\n",
    "# For example, using random tensors (replace with your actual data)\n",
    "batch_size = 8\n",
    "# The input shape must match what EEGNetFeature expects. Here we assume a shape of (1, 1, 256) per sample.\n",
    "# If your EEG data is 2D (channels x signal_length), you might need to adjust the dimensions.\n",
    "input_shape = (num_input, 1, signal_length)  # example shape; adjust as needed\n",
    "\n",
    "x1 = torch.randn(batch_size, *input_shape)\n",
    "x2 = torch.randn(batch_size, *input_shape)\n",
    "\n",
    "# Forward pass through the Siamese network\n",
    "embed1, embed2, distance = siamese_model(x1, x2)\n",
    "print(\"Embedding 1 shape:\", embed1.shape)\n",
    "print(\"Embedding 2 shape:\", embed2.shape)\n",
    "print(\"Distance shape:\", distance.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b30e55",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43ca6c-474c-4cbd-b7cc-bf23146d386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_contrastive_loss(y_true, cos_sim, margin = 0.275):\n",
    "    loss_similar = y_true * torch.pow((1-cos_sim), 2)\n",
    "\n",
    "    loss_dissimilar = (1-y_true) * torch.pow(torch.clamp(cos_sim - margin, min = 0.0), 2)\n",
    "    loss = torch.mean(loss_similar + loss_dissimlar)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d763ce1",
   "metadata": {},
   "source": [
    "### Training Loss and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe76e82-737c-42cd-953f-dce619a65e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate your model and move it to device.\n",
    "siamese_model = SiameseEEGNetCosine().to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "# Split the dataset into training and validation (80%/20% split)\n",
    "dataset_size = len(siamese_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(siamese_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define optimizer (using Adam here)\n",
    "optimizer = optim.Adam(siamese_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Optionally, define a scheduler (e.g., ReduceLROnPlateau) if desired:\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# For tracking best validation loss to save the best model\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    siamese_model.train()  # set model to training mode\n",
    "    running_loss = 0.0\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training step\n",
    "    for batch_idx, (x1, x2, labels) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        labels = labels.to(device)  # Expected shape: (batch_size, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute embeddings and cosine similarity\n",
    "        _, _, cos_sim = siamese_model(x1, x2)\n",
    "        \n",
    "        # Compute loss using cosine-based contrastive loss\n",
    "        loss = cosine_contrastive_loss(labels, cos_sim, margin=margin)\n",
    "        \n",
    "        # Backpropagation and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * x1.size(0)\n",
    "    \n",
    "    # Compute average training loss for the epoch\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation step (without gradient computations)\n",
    "    siamese_model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, labels in val_loader:\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass on validation data\n",
    "            _, _, cos_sim = siamese_model(x1, x2)\n",
    "            loss = cosine_contrastive_loss(labels, cos_sim, margin=margin)\n",
    "            val_running_loss += loss.item() * x1.size(0)\n",
    "    \n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Time: {epoch_duration:.2f}s | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Optionally, step the scheduler:\n",
    "    # scheduler.step(val_loss)\n",
    "    \n",
    "    # Save the model if validation loss decreases\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(siamese_model.state_dict(), 'best_siamese_model.pth')\n",
    "        print(\"  --> Best model saved.\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
